{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import textblob   \n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import numpy as np     \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "\n",
    "Base_url = \"https://uk.reuters.com\"\n",
    "\n",
    "#from reuters oil archive\n",
    "pages = [str(i) for i in range(1,2000)]\n",
    "url_list=[]\n",
    "\n",
    "for page in pages:\n",
    "\n",
    "    url= 'https://uk.reuters.com/news/archive/oilRpt?view=page&page='+page +'&pageSize=10'\n",
    "    url_list.append(url)\n",
    "\n",
    "print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import clear_output\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "requests = 0\n",
    "\n",
    "for _ in range(5):\n",
    "    \n",
    "    requests += 1\n",
    "    sleep(randint(1,3))\n",
    "    current_time = time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    print('Request: {}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create an empty list which will contain the selected news articles \n",
    "List_of_links = [] \n",
    "word1=\"article\"\n",
    "\n",
    "for newsurl in url_list:\n",
    "    response = get(newsurl, headers = headers)\n",
    "    \n",
    "    sleep(randint(1,3))\n",
    "    \n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "    \n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    #page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    sub_links = html_soup.find_all('a')\n",
    "    for links in sub_links:\n",
    "        sp = BeautifulSoup(str(links),'html.parser')  # first convert into a string\n",
    "        tag = sp.a\n",
    "      #if word1 in tag['title'] or word2 in tag['title'] or word3 in tag['title']:\n",
    "        if word1 in tag['href']:\n",
    "            category_links =  Base_url + tag[\"href\"]\n",
    "            List_of_links.append(category_links)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_links = list(set(List_of_links))\n",
    "for q in unique_links: print(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "                   'url_news'  : unique_links,\n",
    "                  })\n",
    "\n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read in links\n",
    "\n",
    "dflinks=pd.read_csv('C:/Users/neil.watt/Documents/PythonScripts/Sentiment/Main/MarketSentiment_Analysis/links.csv')\n",
    "dflinks['url_news']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "unique_links=dflinks['url_news']\n",
    "# Create an empty list which will contain the selected news articles \n",
    "text_body=[]\n",
    "date=[]\n",
    "\n",
    "\n",
    "for selected_links in unique_links:\n",
    "    response = get(selected_links, headers = headers)\n",
    "    sleep(randint(1,3))\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "      # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "        \n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    #retrieve body of article\n",
    "    results_text = html_soup.find(class_='StandardArticleBody_body')\n",
    "    story_text = results_text.get_text()\n",
    "    lower_story_text=story_text.lower()\n",
    "    text_body.append(lower_story_text) \n",
    "    #retrieve date\n",
    "    date_results_text = html_soup.find(class_='ArticleHeader_date')\n",
    "    date_text = date_results_text.get_text()\n",
    "    date.append(date_text) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_articles = pd.DataFrame({\n",
    "                   'text_body'  : text_body, 'date' : date\n",
    "                  })\n",
    "\n",
    "print(df_articles.info())\n",
    "df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_articles.to_csv('df_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfarticles=pd.read_csv('C:/Users/neil.watt/Documents/PythonScripts/Sentiment/Main/MarketSentiment_Analysis/df_articles.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "#first I want to compare textblob inbuild sentiment analysis\n",
    "#here defining functions to clean the text\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
    "\n",
    "\n",
    "#analyze_text\n",
    "def analyze_text(text):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    \n",
    "    #The bottom 25% of sentiment is -0.017\n",
    "    #The top 25% of sentiment is 0.08\n",
    "    \n",
    "    analysis = TextBlob(clean_text(text))\n",
    "    if analysis.sentiment.polarity > 0.08:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity < -0.017:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "   # elif analysis.sentiment.polarity == 0:\n",
    "   #     return 0\n",
    "    #else:\n",
    "    #    return -1\n",
    "    \n",
    "def analyze_text_polarity(text):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    analysis = TextBlob(clean_text(text))\n",
    "    return analysis.sentiment.polarity\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfoil=pd.read_csv('dict.csv')\n",
    "\n",
    "positive_words=dfoil[dfoil[\"Sentiment\"]==\"positive\"]['Word'].values\n",
    "negative_words=dfoil[dfoil[\"Sentiment\"]==\"negative\"]['Word'].values\n",
    "print(negative_words[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def tokenizer(theText):\n",
    "    theTokens = re.findall(r'\\b\\w[\\w-]*\\b', theText)\n",
    "    return theTokens\n",
    "\n",
    "\n",
    "    \n",
    "def calculator(text):\n",
    "    # Count positive words\n",
    "    numPosWords = 0\n",
    "    cleantext = tokenizer((text))\n",
    "    #cleantext = clean_text(text)\n",
    "    for word in cleantext:\n",
    "        if word in positive_words:\n",
    "            numPosWords += 1\n",
    "            \n",
    "    # Count negative words\n",
    "    numNegWords = 0\n",
    "    for word in cleantext:\n",
    "        if word in negative_words:\n",
    "            numNegWords += 1\n",
    "    \n",
    "    sum = (numPosWords - numNegWords)\n",
    "    return sum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute sentiment score given dictionary\n",
    "dfarticles['dict_sentiment'] = np.array([calculator(text) for text in dfarticles['text_body'] ])\n",
    "dfarticles['dict_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute sentiment score given textblob sentiment polarity\n",
    "dfarticles['sentiment_polarity'] = np.array([ analyze_text_polarity(text) for text in dfarticles['text_body'] ])\n",
    "dfarticles['sentiment_polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfarticles['sentiment_polarity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute sentiment score given textblob sentiment (binary)\n",
    "dfarticles['sentiment'] = np.array([ analyze_text(text) for text in dfarticles['text_body'] ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfarticles.to_csv('sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsentiment=pd.read_csv('C:/Users/neil.watt/Documents/PythonScripts/Sentiment/Main/MarketSentiment_Analysis/sentiment_analysis.csv')\n",
    "dfsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_daily.to_csv('mean_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfbrent=pd.read_csv('C:/Users/neil.watt/Documents/PythonScripts/Sentiment/Main/MarketSentiment_Analysis/brent.csv')\n",
    "#dfbrent['Date']\n",
    "dfbrent[\"Date\"]=dfbrent[\"Date\"].astype('datetime64[ns]') # Convert column to date format\n",
    "\n",
    "\n",
    "dfbrent['10_MA_sentiment'] = dfbrent['sentiment'].rolling(window=10).mean()\n",
    "dfbrent['30_MA_sentiment'] = dfbrent['sentiment'].rolling(window=30).mean()\n",
    "dfbrent2=dfbrent.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#0.26 correlatin between 10 day MA sentiment\n",
    "np.corrcoef(dfbrent2['10_MA_sentiment'], dfbrent2[\"Brent\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#0.4 correlation between 30 day MA sentiment\n",
    "np.corrcoef(dfbrent2['30_MA_sentiment'], dfbrent2[\"Brent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "ax1.plot(dfbrent['Date'].astype('O'),  dfbrent2[\"Brent\"], color='black', linewidth=3.3)\n",
    "ax1.set_xlabel('')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "\n",
    "ax1.set_ylabel('Brent', color='black', fontsize=20)\n",
    "ax1.tick_params('y', colors='black')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.xaxis.set_major_locator(dates.MonthLocator(interval=1))\n",
    "\n",
    "ax2.plot(dfbrent['Date'].astype('O'),  dfbrent2['10_MA_sentiment'],'green', linewidth=1.3)\n",
    "ax2.plot(dfbrent['Date'].astype('O'),  dfbrent2['30_MA_sentiment'],'red', linewidth=3.3)\n",
    "ax2.set_ylabel('Sentiment', color='black', fontsize=20)\n",
    "ax2.tick_params('y', colors='black')\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.tight_layout()\n",
    "plt.title('Brent versus Sentiment', fontsize=20)\n",
    "\n",
    "\n",
    "#add legend\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
